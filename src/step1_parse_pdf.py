"""
Step 1: ä½¿ç”¨ Docling è§£æå¤šç¨®æ–‡ä»¶æ ¼å¼ï¼ˆPDFã€DOCXã€PPTXã€åœ–ç‰‡ç­‰ï¼‰ä¸¦è¼¸å‡º Markdown
"""
# Windows éœ€åœç”¨ symlinksï¼Œé¿å… [WinError 1314] ç”¨æˆ¶ç«¯æ²’æœ‰é€™é …ç‰¹æ®Šæ¬Šé™
import os

os.environ.setdefault("HF_HUB_DISABLE_SYMLINKS", "1")
os.environ.setdefault("HF_HUB_DISABLE_SYMLINKS_WARNING", "1")

import sys
import traceback
from pathlib import Path
from typing import List, Dict
import json

# ç¢ºä¿èƒ½å°å…¥ config
sys.path.append(str(Path(__file__).parent.parent))
from config import (
    RAW_DOCS_DIR,
    PROCESSED_MD_DIR,
    SUPPORTED_DOC_EXTENSIONS,
    DOCLING_LAYERED_MODE,
    USE_GRANITE_DOCLING,
    DOCLING_DEVICE,
    DOCLING_NUM_THREADS,
    DOCLING_MAX_PAGES,
    DOCLING_IMAGES_SCALE,
)

try:
    from docling.document_converter import DocumentConverter, PdfFormatOption
    from docling.datamodel.base_models import InputFormat
    from docling.datamodel.pipeline_options import ThreadedPdfPipelineOptions

except ImportError:
    print("âŒ è«‹å…ˆå®‰è£ docling: pip install docling")
    sys.exit(1)

if USE_GRANITE_DOCLING and not DOCLING_LAYERED_MODE:
    try:
        from docling.pipeline.vlm_pipeline import VlmPipeline
        from docling.datamodel.pipeline_options import VlmPipelineOptions
        from docling.datamodel.accelerator_options import AcceleratorOptions
    except ImportError as e:
        print("[WARN] Granite Docling éœ€ VLM æ”¯æ´ï¼Œæ”¹ç”¨é è¨­è§£æ:", e)
        USE_GRANITE_DOCLING = False

# åˆ†å±¤æ¨¡å¼ï¼šStep2 æœƒæŠŠ <!-- image --> æˆ– ![Image](...) æ›æˆ <image path="..." />
try:
    from docling_core.types.doc.base import ImageRefMode
except ImportError:
    ImageRefMode = None

from table_dual_track import apply_table_dual_track


def _collect_doc_files(directory: Path) -> List[Path]:
    """æ”¶é›†ç›®éŒ„ä¸‹æ‰€æœ‰æ”¯æ´æ ¼å¼çš„æª”æ¡ˆ"""
    files = []
    for ext in SUPPORTED_DOC_EXTENSIONS:
        files.extend(directory.glob(f"*{ext}"))
    return sorted(files, key=lambda p: p.name.lower())


class DocumentParser:
    """ä½¿ç”¨ Docling è§£æå¤šç¨®æ–‡ä»¶æ ¼å¼ï¼ˆPDFã€DOCXã€PPTXã€åœ–ç‰‡ç­‰ï¼‰çš„å°è£é¡åˆ¥"""

    def __init__(self):
        # æ”¯æ´çš„æ ¼å¼ï¼ˆDocling æœƒä¾å‰¯æª”åè‡ªå‹•é¸æ“‡å°æ‡‰ pipelineï¼‰
        allowed_formats = [
            InputFormat.PDF,
            InputFormat.DOCX,
            InputFormat.PPTX,
            InputFormat.XLSX,
            InputFormat.HTML,
            InputFormat.MD,
            InputFormat.CSV,
            InputFormat.IMAGE,
        ]
        format_options = {}

        if DOCLING_LAYERED_MODE:
            pdf_opts = ThreadedPdfPipelineOptions(
                generate_picture_images=True,
                generate_page_images=True,
                images_scale=DOCLING_IMAGES_SCALE,
            )
            format_options[InputFormat.PDF] = PdfFormatOption(pipeline_options=pdf_opts)
            print("[OK] åˆ†å±¤æ¨¡å¼ï¼šå¤šæ ¼å¼ Doclingï¼ˆPDF/DOCX/PPTX/åœ–ç‰‡ç­‰ â†’ Markdownï¼‰")
        elif USE_GRANITE_DOCLING:
            accel = AcceleratorOptions(device=DOCLING_DEVICE, num_threads=DOCLING_NUM_THREADS)
            format_options[InputFormat.PDF] = PdfFormatOption(
                pipeline_cls=VlmPipeline,
                pipeline_options=VlmPipelineOptions(accelerator_options=accel),
            )
            print(f"[OK] Granite Docling (VLM)ï¼Œè£ç½®: {DOCLING_DEVICE}")

        self.converter = DocumentConverter(
            allowed_formats=allowed_formats,
            format_options=format_options or {},
        )

    def parse_single_document(self, doc_path: Path) -> Dict:
        """è§£æå–®ä¸€æ–‡ä»¶ï¼ˆPDFã€DOCXã€PPTXã€åœ–ç‰‡ç­‰ï¼‰"""
        print(f"ğŸ“„ é–‹å§‹è§£æ: {doc_path.name}")
        try:
            kwargs = {}
            # åƒ… PDF æ”¯æ´ page_rangeï¼ˆé™åˆ¶é æ•¸ï¼‰
            if doc_path.suffix.lower() == ".pdf" and DOCLING_MAX_PAGES is not None:
                kwargs["page_range"] = (1, DOCLING_MAX_PAGES)
                print(f"   ï¼ˆåƒ…å‰ {DOCLING_MAX_PAGES} é ï¼Œæ¸¬è©¦ç”¨ï¼‰")
            result = self.converter.convert(str(doc_path), **kwargs)

            from docling_core.types.doc import TableItem, PictureItem, TextItem

            try:
                from docling_core.types.doc import DocItemLabel
            except ImportError:
                try:
                    from docling_core.types.doc.labels import DocItemLabel
                except ImportError:
                    DocItemLabel = None

            table_counter = [0]
            elements = []
            for item, level in result.document.iterate_items():
                prov = item.prov[0] if item.prov else None
                bbox = prov.bbox if prov and hasattr(prov, "bbox") and prov.bbox else None

                # ä¾ label å€åˆ† heading èˆ‡ paragraph
                label = "paragraph"
                if DocItemLabel is not None:
                    item_label = getattr(item, "label", None)
                    if item_label is not None:
                        if item_label in (DocItemLabel.SECTION_HEADER, DocItemLabel.TITLE):
                            label = "heading"
                # fallbackï¼šå¾ˆçŸ­ä¸”ä¸åƒå¥å­ â†’ heading å€™é¸ï¼ˆDOCX/PPTX å¸¸æ¼æ¨™ï¼‰
                text = (getattr(item, "text", "") or "").strip()
                if label == "paragraph" and text:
                    if len(text) <= 40 and not any(p in text for p in "ã€‚.!?"):
                        label = "heading"

                element = {
                    "type": "text",
                    "level": level,
                    "text": getattr(item, "text", ""),
                    "label": label,
                    "page_number": getattr(prov, "page_no", None) if prov else None,
                    "bbox": {
                        "left": bbox.l, "top": bbox.t, "right": bbox.r, "bottom": bbox.b,
                        "coord_origin": "CoordOrigin.BOTTOMLEFT"
                    } if bbox else None
                }

                if isinstance(item, TableItem):
                    element["type"] = "table"
                    element["label"] = "table"
                    table_counter[0] += 1
                    element["table_id"] = f"{table_counter[0]:04d}"
                    try:
                        html_content = item.export_to_html(doc=result.document)
                        if html_content.strip() == "<table></table>" or not html_content:
                            element["text"] = item.export_to_markdown(doc=result.document)
                        else:
                            element["text"] = html_content
                    except Exception:
                        element["text"] = item.export_to_markdown(doc=result.document)

                elif isinstance(item, PictureItem):
                    element["type"] = "picture"
                    element["label"] = "picture"
                    element["image"] = f"{item.self_ref.split('/')[-1]}.png"
                    element["caption"] = getattr(item, "caption", "[Image description failed]")
                    element["text"] = element["caption"]

                # éæ¿¾ç©º text elementï¼Œé¿å…é›œè¨Š
                if element["type"] == "text" and not (element.get("text") or "").strip():
                    continue
                elements.append(element)

            if DOCLING_LAYERED_MODE and ImageRefMode is not None:
                md_path = PROCESSED_MD_DIR / (doc_path.stem + ".md")
                (PROCESSED_MD_DIR / "images" / doc_path.stem).mkdir(parents=True, exist_ok=True)
                artifacts_dir = Path("images") / doc_path.stem
                result.document.save_as_markdown(
                    filename=md_path,
                    artifacts_dir=artifacts_dir,
                    image_mode=ImageRefMode.REFERENCED,
                )
                markdown_text = md_path.read_text(encoding="utf-8")
            else:
                markdown_text = result.document.export_to_markdown()

            metadata = {
                "source": doc_path.name,
                "num_pages": len(result.document.pages) if hasattr(result.document, "pages") else 0,
                "title": getattr(result.document, "title", doc_path.stem),
                "elements": elements,
            }

            return {
                "markdown": markdown_text,
                "metadata": metadata,
                "success": True
            }

        except Exception as e:
            print(f"âŒ è§£æå¤±æ•—: {e}")
            traceback.print_exc()
            return {
                "markdown": "",
                "metadata": {},
                "success": False,
                "error": str(e)
            }
    def save_markdown(self, doc_path: Path, result: Dict):
        """å„²å­˜ Markdown åˆ°æª”æ¡ˆï¼ˆå«è¡¨æ ¼é›™è»Œï¼šHTML ä¿çœŸ + TABLE_TEXT æª¢ç´¢ç‰ˆï¼‰"""
        if not result["success"]:
            return

        output_path = PROCESSED_MD_DIR / (doc_path.stem + ".md")

        # è¡¨æ ¼é›™è»Œï¼šplaceholders + elements å›å¡« TABLE_HTML + TABLE_TEXT
        markdown_content = apply_table_dual_track(
            result["markdown"],
            result["metadata"].get("elements", []),
        )

        # å¯«å…¥æ ¼å¼åŒ–å¾Œçš„å…§å®¹ï¼ˆåˆ†å±¤æ¨¡å¼å’Œéåˆ†å±¤æ¨¡å¼éƒ½éœ€è¦å¯«å…¥ï¼‰
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        print(f"âœ… å·²å„²å­˜: {output_path}")

        meta_path = PROCESSED_MD_DIR / (doc_path.stem + "_meta.json")
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(result["metadata"], f, indent=2, ensure_ascii=False)
        print(f"ğŸ“Š Metadata: {meta_path}")
    
    def parse_directory(self, max_files: int = None) -> List[Dict]:
        """æ‰¹æ¬¡è§£æç›®éŒ„ä¸‹æ‰€æœ‰æ”¯æ´æ ¼å¼çš„æª”æ¡ˆ"""
        doc_files = _collect_doc_files(RAW_DOCS_DIR)

        if not doc_files:
            print(f"âš ï¸  åœ¨ {RAW_DOCS_DIR} æ‰¾ä¸åˆ°æ”¯æ´çš„æª”æ¡ˆ")
            print(f"   æ”¯æ´å‰¯æª”å: {', '.join(SUPPORTED_DOC_EXTENSIONS)}")
            return []

        if max_files:
            doc_files = doc_files[:max_files]

        print(f"ğŸ” æ‰¾åˆ° {len(doc_files)} å€‹æª”æ¡ˆ ({', '.join(p.suffix for p in doc_files[:5])}{'...' if len(doc_files) > 5 else ''})")

        results = []
        for doc_path in doc_files:
            result = self.parse_single_document(doc_path)
            if result["success"]:
                self.save_markdown(doc_path, result)
            results.append(result)
        
        # çµ±è¨ˆ
        success_count = sum(1 for r in results if r["success"])
        print(f"\nğŸ“ˆ å®Œæˆ: {success_count}/{len(results)} å€‹æª”æ¡ˆæˆåŠŸè§£æ")
        
        return results


def main():
    """ä¸»ç¨‹å¼ - æ¸¬è©¦è§£æåŠŸèƒ½"""
    print("=" * 60)
    print("Step 1: å¤šæ ¼å¼æ–‡ä»¶è§£æï¼ˆPDF / DOCX / PPTX / åœ–ç‰‡ç­‰ï¼‰")
    print("=" * 60)

    parser = DocumentParser()

    doc_files = _collect_doc_files(RAW_DOCS_DIR)
    if not doc_files:
        print(f"\nâš ï¸  è«‹å…ˆå°‡æ–‡ä»¶æ”¾åˆ°: {RAW_DOCS_DIR}")
        print(f"   æ”¯æ´å‰¯æª”å: {', '.join(SUPPORTED_DOC_EXTENSIONS)}")
        return

    print(f"\nğŸš€ é–‹å§‹è§£ææ‰€æœ‰æª”æ¡ˆ...")
    results = parser.parse_directory(max_files=None)
    
    if results and results[0]["success"]:
        print("\n" + "=" * 60)
        print("âœ… è§£ææˆåŠŸï¼å¯ä»¥æŸ¥çœ‹ç”Ÿæˆçš„ Markdown æª”æ¡ˆ")
        print(f"è¼¸å‡ºç›®éŒ„: {PROCESSED_MD_DIR}")
        print("=" * 60)
    

if __name__ == "__main__":
    main()